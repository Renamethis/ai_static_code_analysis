# CodeBERT
Все представленные модели были обучены на датасете CodeXGlue для решения задачи code refinement.
### codebert.ipynb
Ноутбук, содержащий код для обучения энкодера модели BERT на задаче авторегрессии, т.е. итоговая модель Seq2Seq.
# UniXCoder
### codebert.ipynb
За основу был взят тот-же ноутбук, изменены только базовая модель и был добавлен дополнительный дропаут на выходе из энкодера.
# graphCodeBERT
### graphCodeBERT/
Форк API CodeBERT - https://github.com/microsoft/CodeBERT/tree/master/GraphCodeBERT/refinemen
Представлена базовая модель graphCodeBERT, принимающая информацию из AST-представлений кода. К энкодеру добавлен классический декодер и алгоритм beam search.

- model.py - архитектура модели, реализация beam search
- run.py - токенизация датасета, обучение, валидация.
- run_train.sh - скрипт для запуска run.py с параметрами, на которых я обучал модель.
- parser/ - дополнительные парсеры кода для разных ЯП.
- bleu.py - реализация метрики BLEU


### draft/
Первые попытки обучения llama с ast-графовыми эмбеддингами на датасете MSR20.
